{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayVeer18/CUDA-Programs/blob/main/Dot_Product.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VUVyQ9SyxL_"
      },
      "source": [
        "### Step:1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrsaJ4sJvIm4"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L22-5Cdypas"
      },
      "source": [
        "### Step:2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720SQlYqysuL"
      },
      "source": [
        "\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0hrf4GLy9jm"
      },
      "source": [
        "### Step:3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiqO1_60yuHL",
        "outputId": "a0355f65-b73b-4eef-a280-197575b784fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL1xSN_WzG-Z"
      },
      "source": [
        "### Step-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkYgdns9zJ6P"
      },
      "source": [
        "pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pFUhdY-0oxG"
      },
      "source": [
        "### Step-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxl8VyIJ0nJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253f74d1-f901-4299-8386-28c1f6a59d81"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O84kO0ABJ6SO"
      },
      "source": [
        "### Dot Product using Shared Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOlpluw34Bhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b6fe31-ed52-4c60-9761-79d363463019"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define imin(a,b) (a<b?a:b)\n",
        "\n",
        "const int N = 33*1024;\n",
        "const int threadsperblock = 256;\n",
        "const int blockspergrid = imin(32, (N+threadsperblock-1)/threadsperblock);\n",
        "__global__ void dot(int *a, int *b, int *c){\n",
        "    __shared__ int cache[threadsperblock];\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int cacheindex = threadIdx.x;\n",
        "    int temp = 0;\n",
        "    while(tid < N){\n",
        "        temp += a[tid] * b[tid];\n",
        "        tid += blockDim.x * gridDim.x; \n",
        "    } \n",
        "    cache[cacheindex] = temp;\n",
        "    __syncthreads();\n",
        "    int i = blockDim.x/2;\n",
        "    while(i != 0){\n",
        "        if(cacheindex < i){\n",
        "            cache[cacheindex] += cache[cacheindex + i];\n",
        "            __syncthreads();\n",
        "        }\n",
        "        i /= 2;\n",
        "    }\n",
        "    if(cacheindex == 0){\n",
        "        c[blockIdx.x] = cache[0];\n",
        "    }\n",
        "}\n",
        "int main()\n",
        "{\n",
        "  int *a,*b,*partial_c;\n",
        "  int *da, *db, *dc;\n",
        "  int size = N*sizeof(int);\n",
        "  a = new int[N];\n",
        "  b = new int[N];\n",
        "  //partial_c = (int*)malloc(blockspergrid*sizeof(int));\n",
        "  partial_c = new int[blockspergrid];\n",
        " \n",
        "  cudaMalloc((void **)&da, size);\n",
        "  cudaMalloc((void **)&db, size);\n",
        "  cudaMalloc((void **)&dc, blockspergrid*sizeof(int));\n",
        " int res=0;\n",
        " for(int i=0;i<N;i++){\n",
        "      a[i] = i;\n",
        "      b[i] = i * 2;\n",
        "      res += (a[i] * b[i]);\n",
        "  }\n",
        " \n",
        "  cudaMemcpy(da, a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(db, b, size, cudaMemcpyHostToDevice);\n",
        "  \n",
        "  dot<<<blockspergrid,threadsperblock>>>(da, db, dc);\n",
        "  \n",
        "  cudaMemcpy(partial_c, dc, blockspergrid*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  \n",
        "  int c=0;\n",
        "  for(int i=0;i<blockspergrid;i++){\n",
        "      c+=partial_c[i];\n",
        "  }\n",
        "  printf(\"Dot Product from GPU : %d \\n Dot Product from CPU : %d\",c,res);\n",
        "\n",
        "  cudaFree(da);\n",
        "  cudaFree(db);\n",
        "  cudaFree(dc);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot Product from GPU : 1005595648 \n",
            " Dot Product from CPU : 1005595648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9nexArJ1UP"
      },
      "source": [
        "### Dot Product using Atomics\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fROPAxc3IBNN",
        "outputId": "85cba6f1-37a9-457a-acc2-5b09a552d85d"
      },
      "source": [
        "%%cu\r\n",
        "#include <stdio.h>\r\n",
        "#include <stdlib.h>\r\n",
        "\r\n",
        "const int N = 500;\r\n",
        "__global__ void dotProduct(int *a, int *b, int *c)\r\n",
        "{\r\n",
        "  int i = threadIdx.x;\r\n",
        "  atomicAdd(c, a[i]*b[i]);\r\n",
        " \r\n",
        "}\r\n",
        "int main()\r\n",
        "{\r\n",
        "  int *a,*b;\r\n",
        "  int *da, *db, *dc;\r\n",
        "  int size = N*sizeof(int);\r\n",
        "  a = new int[N];\r\n",
        "  b = new int[N];\r\n",
        "  int res=0,c=0;\r\n",
        "  for(int i=0;i<N;i++){\r\n",
        "        a[i] = i;\r\n",
        "        b[i] = i * 2;\r\n",
        "        res += (a[i] * b[i]);\r\n",
        "    }\r\n",
        "  cudaMalloc((void **)&da, size);\r\n",
        "  cudaMalloc((void **)&db, size);\r\n",
        "  cudaMalloc((void **)&dc, sizeof(int));\r\n",
        " \r\n",
        "  cudaMemcpy(da, a, size, cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(db, b, size, cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(dc, &c, sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "  dotProduct<<<1,N>>>(da, db, dc);\r\n",
        " \r\n",
        "  cudaMemcpy(&c, dc, sizeof(int), cudaMemcpyDeviceToHost);\r\n",
        "  printf(\"Dot Product from GPU : %d \\n Dot Product from CPU : %d\",c,res);\r\n",
        "\r\n",
        "  cudaFree(da);\r\n",
        "  cudaFree(db);\r\n",
        "  cudaFree(dc);\r\n",
        "  return 0;\r\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot Product from GPU : 83083500 \n",
            " Dot Product from CPU : 83083500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdOP2lYFPsXt"
      },
      "source": [
        "***Dot Product using Atomics with Shared Memory***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4o26KjSK5Ml",
        "outputId": "f4c27825-1e62-4cb9-9ab0-7e0e565889fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%cu \r\n",
        "#include<stdio.h>\r\n",
        "using namespace std;\r\n",
        "#define imin(a,b) (a<b?a:b)\r\n",
        "\r\n",
        "const int N = 10;\r\n",
        "const int threadsperblock = 5;\r\n",
        "const int numberOfBlocks = 2;\r\n",
        "\r\n",
        "__global__ void dotProduct(float *a,float *b,float *c,float *d){\r\n",
        "    int threadid = threadIdx.x + blockIdx.x * blockDim.x;\r\n",
        "    int blockid = blockIdx.x;\r\n",
        "    __shared__ float sm[numberOfBlocks];\r\n",
        "    d[threadid] += a[threadid] * b[threadid];\r\n",
        "    atomicAdd(&sm[blockid],d[threadid]);\r\n",
        "    c[blockid] = sm[blockid];\r\n",
        "    __syncthreads();\r\n",
        "}\r\n",
        "int main(){\r\n",
        "    float *a,*b,*c,*d;\r\n",
        "    float *dev_a,*dev_b,*dev_c,*dev_d;\r\n",
        "    int numberOfBytes = N*sizeof(float);\r\n",
        "    a = (float*)malloc(numberOfBytes);\r\n",
        "    b = (float*)malloc(numberOfBytes);\r\n",
        "    c = (float*)malloc(numberOfBytes);\r\n",
        "    d = (float*)malloc(numberOfBytes);\r\n",
        "    for(int i=0;i<N;i++){\r\n",
        "      a[i] = i;\r\n",
        "      b[i] = i * 2;\r\n",
        "  }\r\n",
        "  cudaMalloc((void**)&dev_a,numberOfBytes);\r\n",
        "  cudaMalloc((void**)&dev_b,numberOfBytes);\r\n",
        "  cudaMalloc((void**)&dev_c,numberOfBlocks*sizeof(float));\r\n",
        "  cudaMalloc((void**)&dev_d,numberOfBytes);\r\n",
        "\r\n",
        "  cudaMemcpy(dev_a,a,numberOfBytes,cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(dev_b,b,numberOfBytes,cudaMemcpyHostToDevice);\r\n",
        " \r\n",
        "  cudaMemset(dev_c,0,numberOfBlocks*sizeof(float));\r\n",
        "  cudaMemset(dev_d,0,numberOfBytes);\r\n",
        "\r\n",
        "  cudaEvent_t start,stop;\r\n",
        "  cudaEventCreate(&start);\r\n",
        "  cudaEventCreate(&stop);\r\n",
        "  cudaEventRecord(start,0);\r\n",
        "\r\n",
        "  dotProduct<<<numberOfBlocks,threadsperblock>>>(dev_a,dev_b,dev_c,dev_d);\r\n",
        "\r\n",
        "  cudaEventRecord(stop);\r\n",
        "  cudaEventSynchronize(stop);\r\n",
        "  float time = 0;\r\n",
        "  cudaEventElapsedTime(&time,start,stop);\r\n",
        "\r\n",
        "  cudaMemcpy(c,dev_c,numberOfBlocks*sizeof(float),cudaMemcpyDeviceToHost);\r\n",
        "  cudaMemcpy(d,dev_d,numberOfBytes,cudaMemcpyDeviceToHost);\r\n",
        "  printf(\"Time taken: %f\",time);\r\n",
        "\r\n",
        "  float temp = 0;\r\n",
        "  printf(\"\\na[i]\\t\\tb[i]\\t\\tproduct\\n\");\r\n",
        "  for(int i=0;i<N;i++){\r\n",
        "      printf(\"%f\\t%f\\t%f\\n\",a[i],b[i],d[i]);\r\n",
        "  }\r\n",
        "  for(int i=0;i<numberOfBlocks;i++){\r\n",
        "      temp += c[i];\r\n",
        "  }\r\n",
        "  printf(\"\\n DotProduct...%f\\n\",temp);\r\n",
        "\r\n",
        "  cudaFree(dev_a);\r\n",
        "  cudaFree(dev_b);\r\n",
        "  cudaFree(dev_c);\r\n",
        "  cudaFree(dev_d);\r\n",
        "\r\n",
        "  return 0;\r\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0.034848\n",
            "a[i]\t\tb[i]\t\tproduct\n",
            "0.000000\t0.000000\t0.000000\n",
            "1.000000\t2.000000\t2.000000\n",
            "2.000000\t4.000000\t8.000000\n",
            "3.000000\t6.000000\t18.000000\n",
            "4.000000\t8.000000\t32.000000\n",
            "5.000000\t10.000000\t50.000000\n",
            "6.000000\t12.000000\t72.000000\n",
            "7.000000\t14.000000\t98.000000\n",
            "8.000000\t16.000000\t128.000000\n",
            "9.000000\t18.000000\t162.000000\n",
            "\n",
            " DotProduct...570.000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}